% References for CORE-Bench NeurIPS Paper

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{openai2023gpt4,
  title={GPT-4 technical report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{hendrycks2021measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2021}
}

@article{talmor2019commonsenseqa,
  title={CommonsenseQA: A question answering challenge targeting commonsense knowledge},
  author={Talmor, Alon and Herzig, Jonathan and Lourie, Nicholas and Berant, Jonathan},
  journal={arXiv preprint arXiv:1811.00937},
  year={2019}
}

@article{clark2020transformers,
  title={Transformers as soft reasoners over language},
  author={Clark, Peter and Tafjord, Oyvind and Richardson, Kyle},
  journal={arXiv preprint arXiv:2002.05867},
  year={2020}
}

@article{liu2020logiqa,
  title={LogiQA: A challenge dataset for machine reading comprehension with logical reasoning},
  author={Liu, Jian and Cui, Leyang and Liu, Hanmeng and Huang, Dandan and Wang, Yile and Zhang, Yue},
  journal={arXiv preprint arXiv:2007.08124},
  year={2020}
}

@inproceedings{yu2020reclor,
  title={ReClor: A reading comprehension dataset requiring logical reasoning},
  author={Yu, Weihao and Jiang, Zihang and Dong, Yanfei and Feng, Jiashi},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{geva2021did,
  title={Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies},
  author={Geva, Mor and Khashabi, Daniel and Segal, Elad and Khot, Tushar and Roth, Dan and Berant, Jonathan},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={346--361},
  year={2021}
}

@article{srivastava2023beyond,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={Transactions on Machine Learning Research},
  year={2023}
}

@article{liang2022holistic,
  title={Holistic evaluation of language models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={arXiv preprint arXiv:2211.09110},
  year={2022}
}

@article{zhong2023agieval,
  title={AGIEval: A human-centric benchmark for evaluating foundation models},
  author={Zhong, Wanjun and Cui, Ruixiang and Guo, Yiduo and Liang, Yaobo and Lu, Shuai and Wang, Yanlin and Saied, Amin and Chen, Weizhu and Duan, Nan},
  journal={arXiv preprint arXiv:2304.06364},
  year={2023}
}

@article{chang2023survey,
  title={A survey on evaluation of large language models},
  author={Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  journal={ACM Transactions on Intelligent Systems and Technology},
  year={2023}
}

@book{johnson2010mental,
  title={Mental models: Towards a cognitive science of language, inference, and consciousness},
  author={Johnson-Laird, Philip Nicholas},
  year={2010},
  publisher={Harvard University Press}
}

@book{kahneman2011thinking,
  title={Thinking, fast and slow},
  author={Kahneman, Daniel},
  year={2011},
  publisher={Farrar, Straus and Giroux}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{anthropic2024claude,
  title={The Claude 3 model family: A new standard for intelligence},
  author={Anthropic},
  journal={Anthropic Technical Report},
  year={2024}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Sorber, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{qwen2024qwen,
  title={Qwen technical report},
  author={Qwen Team},
  journal={arXiv preprint arXiv:2309.16609},
  year={2024}
}

@article{deepseek2024deepseek,
  title={DeepSeek-V2: A strong, economical, and efficient mixture-of-experts language model},
  author={DeepSeek-AI},
  journal={arXiv preprint arXiv:2405.04434},
  year={2024}
}

@inproceedings{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  booktitle={International Conference on Machine Learning},
  year={2021}
}

@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}
@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{rousseeuw1987silhouettes,
  title={Silhouettes: a graphical aid to the interpretation and validation of cluster analysis},
  author={Rousseeuw, Peter J},
  journal={Journal of computational and applied mathematics},
  volume={20},
  pages={53--65},
  year={1987},
  publisher={Elsevier}
}

@article{ward1963hierarchical,
  title={Hierarchical grouping to optimize an objective function},
  author={Ward Jr, Joe H},
  journal={Journal of the American statistical association},
  volume={58},
  number={301},
  pages={236--244},
  year={1963},
  publisher={Taylor \& Francis}
}

@article{herfindahl1950concentration,
  title={Concentration in the steel industry},
  author={Herfindahl, Orris C},
  journal={Columbia University},
  year={1950}
}

@book{efron1994introduction,
  title={An introduction to the bootstrap},
  author={Efron, Bradley and Tibshirani, Robert J},
  year={1994},
  publisher={CRC press}
}

@article{cohen1988statistical,
  title={Statistical power analysis for the behavioral sciences},
  author={Cohen, Jacob},
  year={1988},
  publisher={Lawrence Erlbaum Associates}
}

@article{pareto1896cours,
  title={Cours d'{\'e}conomie politique},
  author={Pareto, Vilfredo},
  journal={Librairie Droz},
  year={1896}
}

@article{lorenz1905methods,
  title={Methods of measuring the concentration of wealth},
  author={Lorenz, Max O},
  journal={Publications of the American statistical association},
  volume={9},
  number={70},
  pages={209--219},
  year={1905},
  publisher={Taylor \& Francis}
}

@article{gini1912variabilita,
  title={Variabilit{\`a} e mutabilit{\`a}},
  author={Gini, Corrado},
  journal={Reprinted in Memorie di metodologica statistica},
  year={1912}
}

@article{mannwhitney1947test,
  title={On a test of whether one of two random variables is stochastically larger than the other},
  author={Mann, Henry B and Whitney, Donald R},
  journal={The annals of mathematical statistics},
  pages={50--60},
  year={1947},
  publisher={JSTOR}
}